{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all relevant hashes in dataview\n",
    "\n",
    "schedule item loop -> get_item_views(item, beg_week, end_week)\n",
    "\n",
    "get_item_views updates the relevant dataview hashes including the weekly views for the range of weeks using either caches or creating as needed\n",
    "\n",
    "create_item_views calls the various handlers such as handle_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped text:\n",
      "This is a long string that we want to wrap and\n",
      "   then unwrap. We will use the textwrap\n",
      "   module to handle the wrapping.\n",
      "   This is a new paragraph that should also be\n",
      "   wrapped.\n",
      "     Now is the time for all good men to come\n",
      "   to the aid of their country.\n",
      "     Now is the time for all good men to come\n",
      "   to the aid of their country.\n",
      "     Now is the time for all good men to come\n",
      "   to the aid of their country.\n",
      "     Now is the time for all good men to come\n",
      "   to the aid of their country.\n",
      "     Now is the time for all good men to come\n",
      "   to the aid of their country.\n",
      "\n",
      "\n",
      "Unwrapped text:\n",
      "This is a long string that we want to wrap and then unwrap. We will use the textwrap module to handle the wrapping. This is a new paragraph that should also be wrapped. Now is the time for all good men to come to the aid of their country. Now is the time for all good men to come to the aid of their country. Now is the time for all good men to come to the aid of their country. Now is the time for all good men to come to the aid of their country. Now is the time for all good men to come to the aid of their country.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: unwrap to encode and wrap to decode @d entries?\n",
    "import textwrap\n",
    "import shutil\n",
    "\n",
    "def wrap(txt, indent=1, width=shutil.get_terminal_size()[0] - 3):\n",
    "    para = [x.rstrip() for x in txt.split('\\n')]\n",
    "    tmp = []\n",
    "    first = True\n",
    "    for p in para:\n",
    "        if first:\n",
    "            initial_indent = ''\n",
    "            first = False\n",
    "        else:\n",
    "            initial_indent = ' ' * indent\n",
    "        tmp.append(\n",
    "            textwrap.fill(\n",
    "                p,\n",
    "                initial_indent=initial_indent,\n",
    "                subsequent_indent=' ' * indent,\n",
    "                width=width - indent - 1,\n",
    "            )\n",
    "        )\n",
    "    return '\\n'.join(tmp)\n",
    "\n",
    "def unwrap(wrapped_text):\n",
    "    # Split the text into paragraphs\n",
    "    paragraphs = wrapped_text.split('\\n')\n",
    "\n",
    "    # Remove indentations and join lines within each paragraph\n",
    "    unwrapped_paragraphs = []\n",
    "    current_paragraph = []\n",
    "\n",
    "    for line in paragraphs:\n",
    "        if line.strip() == '':\n",
    "            # Paragraph separator\n",
    "            if current_paragraph:\n",
    "                unwrapped_paragraphs.append(' '.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "            unwrapped_paragraphs.append('')\n",
    "        else:\n",
    "            # Remove leading spaces used for indentation\n",
    "            current_paragraph.append(line.strip())\n",
    "\n",
    "    # Add the last paragraph if there is any\n",
    "    if current_paragraph:\n",
    "        unwrapped_paragraphs.append(' '.join(current_paragraph))\n",
    "\n",
    "    # Join the unwrapped paragraphs\n",
    "    return '\\n'.join(unwrapped_paragraphs)\n",
    "\n",
    "# Example usage\n",
    "original_text = \"\"\"\\\n",
    "This is a long string that we want to wrap and then unwrap. We will use the textwrap module to handle the wrapping.\n",
    "This is a new paragraph that should also be wrapped.\n",
    "\"\"\"\n",
    "original_text += \"  Now is the time for all good men to come to the aid of their country.\\n\" * 5\n",
    "\n",
    "# Wrap the text\n",
    "wrapped_text = wrap(original_text, indent=3, width=50)\n",
    "print(\"Wrapped text:\")\n",
    "print(wrapped_text)\n",
    "\n",
    "# Unwrap the text\n",
    "unwrapped_text = unwrap(wrapped_text)\n",
    "print(\"\\nUnwrapped text:\")\n",
    "print(unwrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(1997, 9, 2, 9, 0),\n",
       " datetime.datetime(1997, 9, 7, 9, 0),\n",
       " datetime.datetime(1997, 9, 12, 9, 0),\n",
       " datetime.datetime(1997, 9, 22, 9, 0),\n",
       " datetime.datetime(1997, 10, 2, 9, 0),\n",
       " datetime.datetime(1997, 10, 12, 9, 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.rrule import rrule, rruleset, rrulestr, DAILY\n",
    "\n",
    "ruleset = rrulestr(\"\"\"\n",
    "DTSTART:19970902T090000\n",
    "RRULE:FREQ=DAILY;INTERVAL=10;COUNT=5\n",
    "RRULE:FREQ=DAILY;INTERVAL=5;COUNT=3\n",
    "\"\"\")\n",
    "\n",
    "list(ruleset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all: ['-1MO', '+2TU', 'WE', '-5TH', '1FR', '-3SA', '5SU'] \n",
      "bad: ['-5TH', '1FR', '5SU'] \n",
      "good: ['-1MO', '+2TU', 'WE', '-3SA']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "wkd_regex = re.compile(r'(?<![\\w-])([+-][1-4])?(MO|TU|WE|TH|FR|SA|SU)(?!\\w)')\n",
    "# wkd_regex = re.compile(r'([+-][1-4])?(MO|TU|WE|TH|FR|SA|SU)')\n",
    "wkd_str = (\"-1MO, +2Tu, WE, -5TH, 1FR, -3SA, 5SU\").upper()\n",
    "matches = wkd_regex.findall(wkd_str)\n",
    "_ = [f\"{x[0]}{x[1]}\" for x in matches]\n",
    "all = [x.strip() for x in wkd_str.split(',')]\n",
    "bad = [x for x in all if x not in good]\n",
    "good = _\n",
    "# for x in matches:\n",
    "#     arg = f\"+{x[0]}\" if x[0] and not x[0].startswith('-') else x[0]\n",
    "#     s = f\"{x[0]{x[1]}({arg})\" if arg else f\"rrule.{x[1]}\"\n",
    "#     good.append(eval(s))\n",
    "\n",
    "print('\\nall:', all, '\\nbad:', bad, '\\ngood:', good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Views\n",
    "\n",
    "- iterate through all items appending relevant \n",
    "\n",
    "- agenda (cached?). Create collects agenda rows from all items, sorts and makes tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "-  _from_entry_string: for Item, Repeat and Jobs. \n",
    "\n",
    "- Clean up Dataview and Item classes - what's actually needed for schedule?\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': '{T}:20240712T1052', 'itemtype': '*', 'summary': 'Thanksgiving', 's': '{T}:20101126T050000', 'r': [{'r': 'y', 'M': [11], 'w': ['4TH']}]}\n",
      "{'created': '20240722T124522', 'itemtype': '*', 'summary': 'Thanksgiving ', 's': '{T}:20101126T000000', 'r': [{'r': 'y', 'M': [11], 'w': ['4TH']}]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from dateutil.rrule import rruleset, rrule, DAILY\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, json_dict=None, input_string=None):\n",
    "        self.created = self._get_current_timestamp()\n",
    "        self.itemtype = None\n",
    "        self.summary = None\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.recurrence = None\n",
    "        self.rruleset = None\n",
    "        if json_dict:\n",
    "            self._init_from_json(json_dict)\n",
    "        elif input_string:\n",
    "            self.parse_input(input_string)\n",
    "\n",
    "    def _get_current_timestamp(self):\n",
    "        return datetime.now(pytz.utc).strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "    def _init_from_json(self, json_dict):\n",
    "        self.created = json_dict.get(\"created\", self.created)\n",
    "        self.itemtype = json_dict.get(\"itemtype\")\n",
    "        self.summary = json_dict.get(\"summary\")\n",
    "        self.start = self._parse_datetime(json_dict.get(\"s\", \"\").replace(\"{T}:\", \"\"))\n",
    "        self.end = self._parse_datetime(json_dict.get(\"e\", \"\").replace(\"{T}:\", \"\"))\n",
    "        self.recurrence = json_dict.get(\"r\", [{}])[0]\n",
    "\n",
    "    def parse_input(self, input_string):\n",
    "        tokens = self._tokenize(input_string)\n",
    "        self._parse_tokens(tokens)\n",
    "        self._validate()\n",
    "\n",
    "    def _tokenize(self, input_string):\n",
    "        pattern = r'(@\\w+ [^@&]+)|(&\\w+ \\S+)|(^\\S+)|(\\S[^@&]*)'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        return [match[0] or match[1] or match[2] or match[3] for match in matches if match[0] or match[1] or match[2] or match[3]]\n",
    "\n",
    "    def _parse_tokens(self, tokens):\n",
    "        self.itemtype = tokens[0][0]\n",
    "        summary_tokens = []\n",
    "        recurrence_attributes = {}\n",
    "        for token in tokens[1:]:\n",
    "            if token.startswith('@'):\n",
    "                break\n",
    "            summary_tokens.append(token)\n",
    "        self.summary = ' '.join(summary_tokens)\n",
    "        for token in tokens[len(summary_tokens) + 1:]:\n",
    "            if token.startswith('@s'):\n",
    "                self.start = self._parse_datetime(token[3:].strip())\n",
    "            elif token.startswith('@e'):\n",
    "                self.end = self._parse_duration(token[3:].strip())\n",
    "            elif token.startswith('@r'):\n",
    "                self.recurrence = self._parse_recurrence(token[3:].strip())\n",
    "            elif token.startswith('&'):\n",
    "                attribute, value = self._parse_attribute(token)\n",
    "                recurrence_attributes[attribute] = value\n",
    "        if self.recurrence:\n",
    "            self.recurrence.update(recurrence_attributes)\n",
    "\n",
    "    def _parse_datetime(self, datetime_str):\n",
    "        if not datetime_str:\n",
    "            return None\n",
    "        try:\n",
    "            return datetime.strptime(datetime_str, \"%Y%m%dT%H%M%S\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.strptime(datetime_str, \"%Y/%m/%d\")\n",
    "            except ValueError:\n",
    "                raise ValueError(f\"Invalid datetime format: {datetime_str}\")\n",
    "\n",
    "    def _parse_duration(self, duration_str):\n",
    "        match = re.match(r'(\\d+)([dwmy])', duration_str)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
    "        value, unit = match.groups()\n",
    "        if unit == 'd':\n",
    "            return timedelta(days=int(value))\n",
    "        elif unit == 'w':\n",
    "            return timedelta(weeks=int(value))\n",
    "        elif unit == 'm':\n",
    "            return timedelta(days=int(value) * 30)\n",
    "        elif unit == 'y':\n",
    "            return timedelta(days=int(value) * 365)\n",
    "\n",
    "    def _parse_recurrence(self, recurrence_str):\n",
    "        return {\"r\": recurrence_str}\n",
    "\n",
    "    def _parse_attribute(self, attribute_str):\n",
    "        key, value = attribute_str[1:].split()\n",
    "        if key == \"M\":\n",
    "            value = [int(value)]\n",
    "        elif key == \"w\":\n",
    "            value = [f\"{value[:1]}TH\"]\n",
    "        return key, value\n",
    "\n",
    "    def _validate(self):\n",
    "        if self.itemtype == '*' and not self.start:\n",
    "            raise ValueError(\"Events must have a start datetime (@s)\")\n",
    "        if self.recurrence and not self.start:\n",
    "            raise ValueError(\"Items with recurrence (@r) must have a start datetime (@s)\")\n",
    "\n",
    "    def to_dict(self):\n",
    "        data = {\n",
    "            \"created\": self.created,\n",
    "            \"itemtype\": self.itemtype,\n",
    "            \"summary\": self.summary,\n",
    "        }\n",
    "        if self.start:\n",
    "            data[\"s\"] = \"{T}:\" + self.start.strftime(\"%Y%m%dT%H%M%S\")\n",
    "        if self.end:\n",
    "            data[\"e\"] = \"{T}:\" + (self.start + self.end).strftime(\"%Y%m%dT%H%M%S\")\n",
    "        if self.recurrence:\n",
    "            data[\"r\"] = [self.recurrence]\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_dict())\n",
    "\n",
    "# Example usage\n",
    "json_entry = {\n",
    "    \"created\": \"{T}:20240712T1052\",\n",
    "    \"itemtype\": \"*\",\n",
    "    \"summary\": \"Thanksgiving\",\n",
    "    \"s\": \"{T}:20101126T0500\",\n",
    "    \"r\": [\n",
    "        {\n",
    "            \"r\": \"y\",\n",
    "            \"M\": [11],\n",
    "            \"w\": [\"4TH\"]\n",
    "        }\n",
    "    ],\n",
    "    \"modified\": \"{T}:20240712T1054\"\n",
    "}\n",
    "\n",
    "item_from_json = Item(json_dict=json_entry)\n",
    "print(item_from_json)\n",
    "\n",
    "item_from_string = Item(input_string=\"* Thanksgiving @s 2010/11/26 @r y &M 11 &w 4TH\")\n",
    "print(item_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dateutil.rrule import rruleset, rrule, DAILY\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, input_string=None):\n",
    "        self.created = self._get_current_timestamp()\n",
    "        self.itemtype = None\n",
    "        self.summary = None\n",
    "        self.start = None\n",
    "        self.end = None\n",
    "        self.recurrence = None\n",
    "        self.rruleset = None\n",
    "        if input_string:\n",
    "            self.parse_input(input_string)\n",
    "\n",
    "    def _get_current_timestamp(self):\n",
    "        return datetime.now(pytz.utc).strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "    def parse_input(self, input_string):\n",
    "        tokens = self._tokenize(input_string)\n",
    "        self._parse_tokens(tokens)\n",
    "        self._validate()\n",
    "\n",
    "    def _tokenize(self, input_string):\n",
    "        pattern = r'(@\\w+ [^@]+)|(^\\S+)|(\\S[^@]*)'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        return [match[0] or match[1] or match[2] for match in matches if match[0] or match[1] or match[2]]\n",
    "\n",
    "    def _parse_tokens(self, tokens):\n",
    "        self.itemtype = tokens[0][0]\n",
    "        summary_tokens = []\n",
    "        for token in tokens[1:]:\n",
    "            if token.startswith('@'):\n",
    "                break\n",
    "            summary_tokens.append(token)\n",
    "        self.summary = ' '.join(summary_tokens)\n",
    "        for token in tokens[len(summary_tokens) + 1:]:\n",
    "            if token.startswith('@s'):\n",
    "                self.start = self._parse_datetime(token[3:].strip())\n",
    "            elif token.startswith('@e'):\n",
    "                self.end = self._parse_duration(token[3:].strip())\n",
    "            elif token.startswith('@r'):\n",
    "                self.recurrence = self._parse_recurrence(token[3:].strip())\n",
    "            # Add additional parsing as needed\n",
    "\n",
    "    def _parse_datetime(self, datetime_str):\n",
    "        try:\n",
    "            return datetime.strptime(datetime_str, \"%Y/%m/%d\")\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Invalid datetime format: {datetime_str}\")\n",
    "\n",
    "    def _parse_duration(self, duration_str):\n",
    "        match = re.match(r'(\\d+)([dwmy])', duration_str)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
    "        value, unit = match.groups()\n",
    "        if unit == 'd':\n",
    "            return timedelta(days=int(value))\n",
    "        elif unit == 'w':\n",
    "            return timedelta(weeks=int(value))\n",
    "        elif unit == 'm':\n",
    "            return timedelta(days=int(value) * 30)\n",
    "        elif unit == 'y':\n",
    "            return timedelta(days=int(value) * 365)\n",
    "\n",
    "    def _parse_recurrence(self, recurrence_str):\n",
    "        # Implement recurrence parsing logic\n",
    "        pass\n",
    "\n",
    "    def _validate(self):\n",
    "        if self.itemtype == '*' and not self.start:\n",
    "            raise ValueError(\"Events must have a start datetime (@s)\")\n",
    "        if self.recurrence and not self.start:\n",
    "            raise ValueError(\"Items with recurrence (@r) must have a start datetime (@s)\")\n",
    "\n",
    "    def to_dict(self):\n",
    "        data = {\n",
    "            \"created\": self.created,\n",
    "            \"itemtype\": self.itemtype,\n",
    "            \"summary\": self.summary,\n",
    "        }\n",
    "        if self.start:\n",
    "            data[\"s\"] = self.start.strftime(\"%Y%m%dT%H%M%S\")\n",
    "        if self.end:\n",
    "            data[\"e\"] = (self.start + self.end).strftime(\"%Y%m%dT%H%M%S\")\n",
    "        if self.recurrence:\n",
    "            data[\"r\"] = self.recurrence\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_dict())\n",
    "\n",
    "# Example usage\n",
    "item = Item(\"* carpe diem @s 2024/7/10 @r d\")\n",
    "print(item)\n",
    "\n",
    "item2 = Item(\"- ask ChatGPT how to fix my code\")\n",
    "print(item2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Date:\n",
    "    def __init__(self, year, month, day):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.day = day\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, date_str):\n",
    "        year, month, day = map(int, date_str.split('-'))\n",
    "        return cls(year, month, day)\n",
    "\n",
    "date1 = Date(2024, 7, 5)\n",
    "date2 = Date.from_string(\"2024-07-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    constants = {\n",
    "        \"pi\": 3.14,\n",
    "        \"e\": 2.71}\n",
    "\n",
    "    @classmethod\n",
    "    def add(cls, a, b):\n",
    "        return cls.constants.get(a, a) + cls.constants.get(b, b)\n",
    "\n",
    "    @classmethod\n",
    "    def subtract(cls, a, b):\n",
    "        return cls.constants.get(a, a) - cls.constants.get(b, b)\n",
    "\n",
    "print(Calculator.add(5, 3))\n",
    "print(Calculator.subtract(5, 3))\n",
    "print(Calculator.add(5, \"pi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'three', 'b': 'two'}\n",
      "no_r = RDATE:2024-07-20 13:00:00\n",
      "RDATE:2024-07-25 13:00:00\n",
      "no_r dates: [datetime.datetime(2024, 7, 20, 13, 0), datetime.datetime(2024, 7, 25, 13, 0)]\n",
      "rules_lst = ['DTSTART:20240720T130000\\nRRULE:FREQ=DAILY;COUNT=14', 'DTSTART:20240723T095034\\nRRULE:FREQ=DAILY;INTERVAL=2;COUNT=7']\n",
      "\n",
      "rules:\n",
      "DTSTART:20240720T130000\\nRRULE:FREQ=DAILY;COUNT=14\n",
      "DTSTART:20240723T095034\\nRRULE:FREQ=DAILY;INTERVAL=2;COUNT=7\n",
      "EXDATE:2024-11-04 13:30:00\n",
      "RDATE:2024-11-04 13:45:00\n",
      "RDATE:2024-11-05 15:15:00\n",
      "rules12.__dict__ = {'_cache': None, '_cache_complete': False, '_len': 23, '_rrule': [<dateutil.rrule.rrule object at 0x107133b60>, <dateutil.rrule.rrule object at 0x1108c8b00>], '_rdate': [datetime.datetime(2024, 11, 4, 13, 45), datetime.datetime(2024, 11, 5, 15, 15)], '_exrule': [], '_exdate': [datetime.datetime(2024, 11, 4, 13, 30)]}\n",
      "\n",
      "occurrences from rules1:\n",
      "  Sat 2024-07-20 13:00  \n",
      "  Sun 2024-07-21 13:00  \n",
      "  Mon 2024-07-22 13:00  \n",
      "  Tue 2024-07-23 13:00  \n",
      "  Wed 2024-07-24 13:00  \n",
      "  Thu 2024-07-25 13:00  \n",
      "  Fri 2024-07-26 13:00  \n",
      "  Sat 2024-07-27 13:00  \n",
      "  Sun 2024-07-28 13:00  \n",
      "  Mon 2024-07-29 13:00  \n",
      "  Tue 2024-07-30 13:00  \n",
      "  Wed 2024-07-31 13:00  \n",
      "  Thu 2024-08-01 13:00  \n",
      "  Fri 2024-08-02 13:00  \n",
      "  Mon 2024-11-04 13:45  \n",
      "  Tue 2024-11-05 15:15  \n",
      "\n",
      "occurrences from rules2:\n",
      "  Tue 2024-07-23 09:50  \n",
      "  Thu 2024-07-25 09:50  \n",
      "  Sat 2024-07-27 09:50  \n",
      "  Mon 2024-07-29 09:50  \n",
      "  Wed 2024-07-31 09:50  \n",
      "  Fri 2024-08-02 09:50  \n",
      "  Sun 2024-08-04 09:50  \n",
      "  Mon 2024-11-04 13:45  \n",
      "  Tue 2024-11-05 15:15  \n",
      "\n",
      "occurrences from rules12:\n",
      "  Sat 2024-07-20 13:00  \n",
      "  Sun 2024-07-21 13:00  \n",
      "  Mon 2024-07-22 13:00  \n",
      "  Tue 2024-07-23 09:50  \n",
      "  Tue 2024-07-23 13:00  \n",
      "  Wed 2024-07-24 13:00  \n",
      "  Thu 2024-07-25 09:50  \n",
      "  Thu 2024-07-25 13:00  \n",
      "  Fri 2024-07-26 13:00  \n",
      "  Sat 2024-07-27 09:50  \n",
      "  Sat 2024-07-27 13:00  \n",
      "  Sun 2024-07-28 13:00  \n",
      "  Mon 2024-07-29 09:50  \n",
      "  Mon 2024-07-29 13:00  \n",
      "  Tue 2024-07-30 13:00  \n",
      "  Wed 2024-07-31 09:50  \n",
      "  Wed 2024-07-31 13:00  \n",
      "  Thu 2024-08-01 13:00  \n",
      "  Fri 2024-08-02 09:50  \n",
      "  Fri 2024-08-02 13:00  \n",
      "  Sun 2024-08-04 09:50  \n",
      "  Mon 2024-11-04 13:45  \n",
      "  Tue 2024-11-05 15:15  \n"
     ]
    }
   ],
   "source": [
    "# FIXME: not working\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil import rrule\n",
    "from dateutil.rrule import rruleset, DAILY, rrulestr\n",
    "from dateutil.tz import gettz\n",
    "import textwrap\n",
    "\n",
    "print(f\"{dict(a='three', b='two')}\")\n",
    "\n",
    "# def is_naive(dt):\n",
    "#     return dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None\n",
    "\n",
    "# Function to create a string representation of the rruleset\n",
    "def rruleset_to_string(rruleset_obj):\n",
    "    parts = []\n",
    "    # parts.append(\"rrules:\")\n",
    "    for rule in rruleset_obj._rrule:\n",
    "        # parts.append(f\"{textwrap.fill(str(rule))}\")\n",
    "        parts.append(f\"{'\\\\n'.join(str(rule).split('\\n'))}\")\n",
    "    # parts.append(\"exdates:\")\n",
    "    for exdate in rruleset_obj._exdate:\n",
    "        parts.append(f\"EXDATE:{exdate}\")\n",
    "    # parts.append(\"rdates:\")\n",
    "    for rdate in rruleset_obj._rdate:\n",
    "        parts.append(f\"RDATE:{rdate}\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Define the timezone (replace 'America/New_York' with your specific timezone)\n",
    "pacific = gettz('US/Pacific')\n",
    "mountain = gettz('America/Denver')\n",
    "central = gettz('US/Central')\n",
    "eastern = gettz('America/New_York')\n",
    "local = gettz()\n",
    "utc = gettz('UTC')\n",
    "naive = None\n",
    "\n",
    "tz = naive\n",
    "# Define the start date\n",
    "start_date = datetime(2024,7,20,13,0,0).astimezone().replace(tzinfo=None)\n",
    "\n",
    "\n",
    "def dt_to_naive(dt):\n",
    "    return dt if dt.tzinfo is None or dt.tzinfo.utcoffset(dt) is None else dt.replace(tzinfo=None)\n",
    "\n",
    "no_r = rruleset()\n",
    "no_r.rdate(start_date)\n",
    "no_r.rdate(start_date + timedelta(days=5))\n",
    "print(f\"no_r = {rruleset_to_string(no_r)}\")\n",
    "print(f\"no_r dates: {list(no_r)}\")\n",
    "\n",
    "rules_lst = []\n",
    "\n",
    "# Create a recurrence rule for daily events\n",
    "rule1 = rrule.rrule(freq=DAILY, dtstart=start_date, count=14)\n",
    "rules_lst.append(str(rule1))\n",
    "# Create another recurrence rule for specific days (e.g., every 2 days)\n",
    "rule2 = rrule.rrule(freq=DAILY, interval=2, count=7)\n",
    "rules_lst.append(str(rule2))\n",
    "print(f\"{rules_lst = }\")\n",
    "\n",
    "# Create an rruleset\n",
    "rules1 = rruleset()\n",
    "rules2 = rruleset()\n",
    "rules12 = rruleset()\n",
    "\n",
    "# Add the rules to the rruleset\n",
    "rules1.rrule(rule1)\n",
    "rules2.rrule(rule2)\n",
    "rules12.rrule(rule1)\n",
    "rules12.rrule(rule2)\n",
    "\n",
    "# Add a specific date to include\n",
    "plusdates = [datetime(2024, 11, 4, 13, 45, tzinfo=tz), datetime(2024, 11, 5, 15, 15, tzinfo=tz)]\n",
    "for dt in plusdates:\n",
    "    dt = dt_to_naive(dt)\n",
    "    rules1.rdate(dt)  # dt_to_naive(dt)\n",
    "    rules2.rdate(dt)  # dt_to_naive(dt)\n",
    "    rules12.rdate(dt)  # dt_to_naive(dt)\n",
    "    rules_lst.append(dt.strftime(\"RDATE:%Y%m%dT%H%M%S\"))\n",
    "\n",
    "# Add a specific date to exclude\n",
    "minusdates = [datetime(2024, 11, 4, 13, 30, tzinfo=tz),]\n",
    "for dt in minusdates:\n",
    "    dt = dt_to_naive(dt)\n",
    "    rules12.exdate(dt)\n",
    "    rules_lst.append(dt.strftime(\"EXDATE:%Y%m%dT%H%M%S\"))\n",
    "\n",
    "# Generate the occurrences of the event\n",
    "occurrences1 = list(rules1)\n",
    "occurrences2 = list(rules2)\n",
    "occurrences12 = list(rules12)\n",
    "\n",
    "# xafter_eg = rules12.xafter(start_date, count=3, inc=True)\n",
    "# print(f\"xafter_eg = {list(after_eg) = }\")\n",
    "\n",
    "# between_eg = rules12.between(datetime.now(), datetime.now() + timedelta(days=14), count=3, inc=True)\n",
    "# print(f\"between_eg = {list(between_eg) = }\")\n",
    "\n",
    "print(f\"\\nrules:\")\n",
    "print(rruleset_to_string(rules12))\n",
    "print(f\"{rules12.__dict__ = }\")\n",
    "\n",
    "# Print the occurrences\n",
    "print(\"\\noccurrences from rules1:\")\n",
    "for occurrence in occurrences1:\n",
    "    print(occurrence.strftime(\"  %a %Y-%m-%d %H:%M %Z %z\"))\n",
    "\n",
    "print(\"\\noccurrences from rules2:\")\n",
    "for occurrence in occurrences2:\n",
    "    print(occurrence.strftime(\"  %a %Y-%m-%d %H:%M %Z %z\"))\n",
    "\n",
    "print(\"\\noccurrences from rules12:\")\n",
    "for occurrence in occurrences12:\n",
    "    print(occurrence.strftime(\"  %a %Y-%m-%d %H:%M %Z %z\"))\n",
    "\n",
    "# print(\"\\nlist of string representations of rules:\")\n",
    "# print('\\n'.join(rules_lst))\n",
    "\n",
    "# print(\"\\nfrom list of string representations to new rules:\")\n",
    "# rules_from_str = rrulestr('\\n'.join(rules_lst))\n",
    "# print(rruleset_to_string(rules_from_str))\n",
    "\n",
    "# occurrences_from_str = list(rules_from_str)\n",
    "# print(\"\\noccurrences from new rules:\")\n",
    "# for occurrence in occurrences_from_str:\n",
    "#     print(occurrence.strftime(\"  %a %Y-%m-%d %H:%M %Z %z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: ['MO', '-1TU', '4FR', 'WE', 'SA', '-3MO', '2WE', '-4FR']\n",
      "all: ['MO', '-1TU', '4FR', 'WE', 'SA', '-3MO', '2WE', '-4FR', '5FR', 'XYZ', '-5MO']\n",
      "bad: ['5FR', 'XYZ', '-5MO']\n",
      "[('', 'MO'), ('-1', 'TU'), ('4', 'FR'), ('', 'WE'), ('', 'SA'), ('-3', 'MO'), ('2', 'WE'), ('-4', 'FR')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = re.compile(r'(?<![\\w-])(-?[1-4]?)(MO|TU|WE|TH|FR|SA|SU)(?!\\w)')\n",
    "\n",
    "# Example test string\n",
    "test_string = \"MO, -1TU, 4FR, WE, SA, -3MO, 2WE, -4FR, 5FR, XYZ, -5MO\"\n",
    "\n",
    "# Find all matches\n",
    "matches = re.findall(pattern, test_string)\n",
    "\n",
    "def maybe_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return x\n",
    "\n",
    "good = [f\"{maybe_int(x[0])}{x[1]}\" for x in matches]\n",
    "all = [x.strip() for x in test_string.split(',')]\n",
    "bad = [x for x in all if x not in good]\n",
    "\n",
    "print(\"good:\", good)\n",
    "print(\"all:\", all)\n",
    "print(\"bad:\", bad)\n",
    "\n",
    "# Print the matches\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Tracking\n",
    "## Tracking\n",
    "\n",
    "For undated tasks, add option for adding @o t to add completions to @h instead of simply marking the task as completed by adding an @f entry.\n",
    "\n",
    "One possibility would be to have @h be a tuple of (number of completions, average timedelta between completions, datetime of last completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating manager\n",
      "adding tracker for bird feeder\n",
      "1: Recorded 2024-06-23 17:38 as a completion  fill bird feeders:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: 2024-06-23 17:38\n",
      "    next_expected_completion: \n",
      "1: Recorded 2024-07-06 16:44 as a completion  fill bird feeders:\n",
      "    completion intervals: 1\n",
      "    average interval: 12 days, 23:06:00\n",
      "    last interval: 12 days, 23:06:00\n",
      "    last_completion: 2024-07-06 16:44\n",
      "    next_expected_completion: 2024-07-19 15:50\n",
      "1: Recorded 2024-07-21 16:18 as a completion  fill bird feeders:\n",
      "    completion intervals: 2\n",
      "    average interval: 13 days, 23:20:00\n",
      "    last interval: 14 days, 23:34:00\n",
      "    last_completion: 2024-07-21 16:18\n",
      "    next_expected_completion: 2024-08-04 15:38\n",
      "1: Recorded 2024-07-26 15:00 as a completion  fill bird feeders:\n",
      "    completion intervals: 3\n",
      "    average interval: 10 days, 23:07:20\n",
      "    last interval: 4 days, 22:42:00\n",
      "    last_completion: 2024-07-26 15:00\n",
      "    next_expected_completion: 2024-08-06 14:07\n",
      "1: Recorded 2024-08-02 16:00 as a completion  fill bird feeders:\n",
      "    completion intervals: 4\n",
      "    average interval: 9 days, 23:35:30\n",
      "    last interval: 7 days, 1:00:00\n",
      "    last_completion: 2024-08-02 16:00\n",
      "    next_expected_completion: 2024-08-12 15:35\n",
      "2: Recorded 2024-08-03 18:35 as a completion  fill water dispenser:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: 2024-08-03 18:35\n",
      "    next_expected_completion: \n",
      "adding tracker for test\n",
      "5: Recorded 2024-07-20 13:45 as a completion  test tracker:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: 2024-07-20 13:45\n",
      "    next_expected_completion: \n",
      "5: Recorded 2024-07-22 15:15 as a completion  test tracker:\n",
      "    completion intervals: 1\n",
      "    average interval: 2 days, 1:30:00\n",
      "    last interval: 2 days, 1:30:00\n",
      "    last_completion: 2024-07-22 15:15\n",
      "    next_expected_completion: 2024-07-24 16:45\n",
      "5: Recorded 2024-07-25 09:45 as a completion  test tracker:\n",
      "    completion intervals: 2\n",
      "    average interval: 2 days, 10:00:00\n",
      "    last interval: 2 days, 18:30:00\n",
      "    last_completion: 2024-07-25 09:45\n",
      "    next_expected_completion: 2024-07-27 19:45\n",
      "5: Recorded 2024-07-26 18:15 as a completion  test tracker:\n",
      "    completion intervals: 3\n",
      "    average interval: 2 days, 1:30:00\n",
      "    last interval: 1 day, 8:30:00\n",
      "    last_completion: 2024-07-26 18:15\n",
      "    next_expected_completion: 2024-07-28 19:45\n",
      "\n",
      "all manager data:\n",
      "1: fill bird feeders:\n",
      "    completion intervals: 4\n",
      "    average interval: 9 days, 23:35:30\n",
      "    last interval: 7 days, 1:00:00\n",
      "    last_completion: 2024-08-02 16:00\n",
      "    next_expected_completion: 2024-08-12 15:35\n",
      "2: fill water dispenser:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: 2024-08-03 18:35\n",
      "    next_expected_completion: \n",
      "3: haircut:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: \n",
      "    next_expected_completion: \n",
      "4: fill cat feeder:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: \n",
      "    next_expected_completion: \n",
      "5: test tracker:\n",
      "    completion intervals: 3\n",
      "    average interval: 2 days, 1:30:00\n",
      "    last interval: 1 day, 8:30:00\n",
      "    last_completion: 2024-07-26 18:15\n",
      "    next_expected_completion: 2024-07-28 19:45\n",
      "1: fill bird feeders\n",
      "2: fill water dispenser\n",
      "3: haircut\n",
      "4: fill cat feeder\n",
      "5: test tracker\n",
      "1: fill bird feeders:\n",
      "    completion intervals: 4\n",
      "    average interval: 9 days, 23:35:30\n",
      "    last interval: 7 days, 1:00:00\n",
      "    last_completion: 2024-08-02 16:00\n",
      "    next_expected_completion: 2024-08-12 15:35\n",
      "2: fill water dispenser:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: 2024-08-03 18:35\n",
      "    next_expected_completion: \n",
      "3: haircut:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: \n",
      "    next_expected_completion: \n",
      "4: fill cat feeder:\n",
      "    completion intervals: 0\n",
      "    average interval: 0:00:00\n",
      "    last interval: None\n",
      "    last_completion: \n",
      "    next_expected_completion: \n",
      "5: test tracker:\n",
      "    completion intervals: 3\n",
      "    average interval: 2 days, 1:30:00\n",
      "    last interval: 1 day, 8:30:00\n",
      "    last_completion: 2024-07-26 18:15\n",
      "    next_expected_completion: 2024-07-28 19:45\n",
      "manager.__repr__() = None\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Tracker and TrackerManager Classes\n",
    "from typing import List, Dict, Any, Callable, Mapping\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.parser import parse\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "default_history = [0, timedelta(minutes=0), None]\n",
    "ZERO = timedelta(minutes=0)\n",
    "\n",
    "class Tracker:\n",
    "    _next_id = 1\n",
    "    default_history = [0, timedelta(minutes=0), None]\n",
    "\n",
    "    @classmethod\n",
    "    def format_dt(self, dt: Any) -> str:\n",
    "        if not isinstance(dt, datetime):\n",
    "            return \"\"\n",
    "        return dt.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    @classmethod\n",
    "    def parse_dt(self, dt: str = \"\") -> datetime:\n",
    "        # print(f\"parsing {dt = }; type(dt) = {type(dt)}\")\n",
    "        if isinstance(dt, datetime):\n",
    "            return dt\n",
    "        elif isinstance(dt, str) and dt:\n",
    "            try:\n",
    "                # print(f\"parsing {dt = }\")\n",
    "                dt = parse(dt)\n",
    "                # print(f\"returning {dt = }\")\n",
    "                return dt\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing datetime: {dt}\\ne {repr(e)}\\n{traceback.format_exc()}\", file=sys.stderr, flush=True)\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __init__(self, name: str, dt: str = \"\") -> None:\n",
    "        self.doc_id = Tracker._next_id\n",
    "        Tracker._next_id += 1\n",
    "        self.name = name\n",
    "        self.last_completion = None\n",
    "        self.last_interval = None\n",
    "        self.next_expected_completion = None\n",
    "        self.history = Tracker.default_history\n",
    "\n",
    "    def record_completion(self, dt):\n",
    "        self.last_completion = Tracker.parse_dt(dt)\n",
    "        # print(f\"{dt = } -> {self.last_completion = }\")\n",
    "        # print(f\"self.last_completion: {Tracker.format_dt(self.last_completion)}\")\n",
    "\n",
    "        num_intervals, average_interval, last_completion = self.history\n",
    "        if last_completion is None:\n",
    "            num_intervals = 0\n",
    "            average_interval = ZERO\n",
    "            last_completion = self.last_completion\n",
    "        else:\n",
    "            self.last_interval = self.last_completion - last_completion\n",
    "            total = num_intervals * average_interval + self.last_interval\n",
    "            num_intervals += 1\n",
    "            average_interval = total / num_intervals\n",
    "\n",
    "        self.history = [num_intervals, average_interval, self.last_completion]\n",
    "        self\n",
    "        self.next_expected_completion = self.last_completion + average_interval if (self.last_completion is not None and self.history[1] is not ZERO) else None\n",
    "\n",
    "    def get_tracker_data(self):\n",
    "        # print(f\"{self.history = }\")\n",
    "        return f\"\"\"{self.name}:\n",
    "    completion intervals: {self.history[0]}\n",
    "    average interval: {str(self.history[1])}\n",
    "    last interval: {str(self.last_interval)}\n",
    "    last_completion: {Tracker.format_dt(self.last_completion)}\n",
    "    next_expected_completion: {Tracker.format_dt(self.next_expected_completion)}\"\"\"\n",
    "\n",
    "class TrackerManager:\n",
    "    def __init__(self) -> None:\n",
    "        self.trackers = {}\n",
    "\n",
    "    def add_tracker(self, tracker) -> None:\n",
    "        doc_id = tracker.doc_id\n",
    "        self.trackers[doc_id] = tracker\n",
    "\n",
    "    def record_completion(self, doc_id: int, dt: datetime):\n",
    "        self.trackers[doc_id].record_completion(dt)\n",
    "        print(f\"\"\"\\\n",
    "{doc_id}: Recorded {dt.strftime('%Y-%m-%d %H:%M')} as a completion  {self.trackers[doc_id].get_tracker_data()}\"\"\")\n",
    "\n",
    "    def get_tracker_data(self, doc_id: int = None):\n",
    "        if doc_id is None:\n",
    "            for k, v in self.trackers.items():\n",
    "                print(f\"{k}: {v.get_tracker_data()}\")\n",
    "        elif doc_id in self.trackers:\n",
    "            print(f\"{doc_id}: {self.trackers[doc_id].get_tracker_data()}\")\n",
    "\n",
    "    def list_trackers(self):\n",
    "        for k, v in self.trackers.items():\n",
    "            print(f\"{k}: {v.name}\")\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        for key, tracker in self.trackers.items():\n",
    "            print(f\"{key}: {tracker.get_tracker_data()}\")\n",
    "\n",
    "print(\"creating manager\")\n",
    "manager = TrackerManager()\n",
    "print(\"adding tracker for bird feeder\")\n",
    "manager.add_tracker(Tracker(\"fill bird feeders\"))\n",
    "datetimes = [parse(\"2024/6/23 5:38p\"),  parse(\"2024/7/6 4:44p\"), parse(\"2024/7/21 4:18p\"), parse(\"2024/7/26 3pm\"), parse(\"2024/8/2/4p\")]\n",
    "for dt in datetimes:\n",
    "    manager.record_completion(1, dt)\n",
    "\n",
    "for name in ['fill water dispenser', 'haircut', 'fill cat feeder']:\n",
    "    manager.add_tracker(Tracker(name))\n",
    "\n",
    "manager.record_completion(2, parse(\"6:35p\"))\n",
    "\n",
    "datetimes = [datetime(2024, 7, 20, 13, 45), datetime(2024, 7, 22, 15, 15), datetime(2024, 7, 25, 9, 45), datetime(2024, 7, 26, 18, 15)]\n",
    "print(\"adding tracker for test\")\n",
    "manager.add_tracker(Tracker(\"test tracker\"))\n",
    "for dt in datetimes:\n",
    "    manager.record_completion(5, dt)\n",
    "\n",
    "print(\"\\nall manager data:\")\n",
    "manager.get_tracker_data()\n",
    "manager.list_trackers()\n",
    "print(f\"{manager.__repr__() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1MO -> Integer part: 1 (type: <class 'str'>), String part: MO\n",
      "Original: -2T -> Integer part: -2 (type: <class 'str'>), String part: T\n",
      "Original: S -> Integer part: None (type: <class 'NoneType'>), String part: S\n",
      "Original: +1FD -> Integer part: +1 (type: <class 'str'>), String part: FD\n",
      "Original: -3WD -> Integer part: -3 (type: <class 'str'>), String part: WD\n",
      "Original:  -> Integer part: None (type: <class 'NoneType'>), String part: \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_int_and_str(s):\n",
    "    # Define a regular expression to match an optional sign followed by digits\n",
    "    weekdays = ['MO', 'TU', 'WE', 'TH', 'FR', 'SA', 'SU']\n",
    "    weekday_str = ','.join(weekdays)\n",
    "    match = re.match(r'^([+-]?\\d*)(.*)$', s)\n",
    "    if match:\n",
    "        integer_part = match.group(1)\n",
    "        string_part = match.group(2)\n",
    "        # Convert integer_part to an integer if it's not empty, otherwise None\n",
    "        integer_part = integer_part if integer_part else None\n",
    "        # problems = []\n",
    "        # if string_part not in weekdays:\n",
    "        #     problems.append(f\"'{string_part}' is not a valid weekday from  {weekday_str}\")\n",
    "\n",
    "\n",
    "        return integer_part, string_part\n",
    "    return None, s  # Default case if no match is found\n",
    "\n",
    "# Example usage\n",
    "examples = ['1MO', '-2T', 'S', '+1FD', '-3WD', '']\n",
    "\n",
    "for example in examples:\n",
    "    integer_part, string_part = get_int_and_str(example)\n",
    "    print(f\"Original: {example} -> Integer part: {integer_part} (type: {type(integer_part)}), String part: {string_part}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "I'd like to dispatch the \"&\" tokens in @r and @j in much the same way as the \"@\" tokens are dispatched but from do_rrule() and do_jobs(), respectively. For the \"&\" tokens for @r, I would like to preface the key in token_keys with an \"r\" so that the key for \"&w\" would become:\n",
    "    'rw': [\n",
    "        'weekdays',\n",
    "        'list from SU, MO, ..., SA, possibly prepended with a positive or negative integer',\n",
    "        'do_weekdays',\n",
    "    ],\n",
    "and similarly the keys for \"@j\" would be prefaced with a \"j\". Since the rruleset components will be stored as strings, I would like to avoid the use of rrule objects such as DAILY and MO and just use strings. As an example:\n",
    "    @classmethod\n",
    "    def do_weekdays(cls, wkd_str: str):\n",
    "        \"\"\"\n",
    "        Converts a string representation of weekdays into a list of rrule objects.\n",
    "        \"\"\"\n",
    "        wkd_str = wkd_str.upper()\n",
    "        wkd_regex = r'(?<![\\w-])([+-][1-4])?(MO|TU|WE|TH|FR|SA|SU)(?!\\w)'\n",
    "        matches = re.findall(wkd_regex, wkd_str)\n",
    "        _ = [f\"{x[0]}{x[1]}\" for x in matches]\n",
    "        all = [x.strip() for x in wkd_str.split(',')]\n",
    "        bad = [x for x in all if x not in _]\n",
    "        problem_str = \"\"\n",
    "        problems = []\n",
    "        for x in bad:\n",
    "            probs = []\n",
    "            print(f\"spliting {x}\")\n",
    "            i, w = cls.split_int_str(x)\n",
    "            if i is not None:\n",
    "                abs_i = abs(int(i))\n",
    "                if abs_i > 4 or abs_i == 0:\n",
    "                    probs.append(f\"{i} must be between -4 and -1 or between +1 and +4\")\n",
    "                elif not (i.startswith('+') or i.startswith('-')):\n",
    "                    probs.append(f\"{i} must begin with '+' or '-'\")\n",
    "            if w not in cls.wkd_list:\n",
    "                probs.append(f\"{w} mug;st be a weekday abbreviation from {cls.wkd_str}\")\n",
    "            if probs:\n",
    "                problems.append(f\"In '{x}': {', '.join(probs)}\")\n",
    "            else:\n",
    "                # undiagnosed problem\n",
    "                problems.append(f\"{x} is invalid\")\n",
    "        if problems:\n",
    "            problem_str = wrap(f\"Problem entries: {', '.join(bad)}\\n{'\\n'.join(problems)}\")\n",
    "        good = []\n",
    "        for x in matches:\n",
    "            s = f\"{x[0]}{x[1]}\" if x[0] else f\"{x[1]}\"\n",
    "            good.append(s)\\\n",
    "        good_str = ','.join(good)\n",
    "        if problem_str:\n",
    "            return False, f\"{problem_str}\\n{good_str}\"\n",
    "        else:\n",
    "            return True, good_str\n",
    "\n",
    "    @classmethod\n",
    "    def split_int_str(cls, s):\n",
    "        match = re.match(r'^([+-]?\\d*)(.*)$', s)\n",
    "        if match:\n",
    "            integer_part = match.group(1)\n",
    "            string_part = match.group(2)\n",
    "            # Convert integer_part to an integer if it's not empty, otherwise None\n",
    "            integer_part = integer_part if integer_part else None\n",
    "            return integer_part, string_part\n",
    "        return None, s  # Default case if no match is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "parsing partial_strings\n",
      "\n",
      "processing: \n",
      "entry to tokens:\n",
      "   ||\n",
      "   ||\n",
      "   []\n",
      "\n",
      "processing: - \n",
      "entry to tokens:\n",
      "   |12|\n",
      "   |- |\n",
      "   [('-', 0, 1)]\n",
      "Dispatching token: - as itemtype\n",
      "Processing item type token: -\n",
      "\n",
      "processing: - T\n",
      "entry to tokens:\n",
      "   |123|\n",
      "   |- T|\n",
      "   [('-', 0, 1), ('T', 2, 3)]\n",
      "processing changed token: ('T', 2, 3)\n",
      "Dispatching token: T as summary\n",
      "Processing summary token: T\n",
      "\n",
      "processing: - Thanksgiving \n",
      "entry to tokens:\n",
      "   |123456789012345|\n",
      "   |- Thanksgiving |\n",
      "   [('-', 0, 1), ('Thanksgiving ', 2, 15)]\n",
      "processing changed token: ('Thanksgiving ', 2, 15)\n",
      "Dispatching token: Thanksgiving  as summary\n",
      "Processing summary token: Thanksgiving \n",
      "\n",
      "processing: - Thanksgiving @\n",
      "entry to tokens:\n",
      "   |1234567890123456|\n",
      "   |- Thanksgiving @|\n",
      "   [('-', 0, 1), ('Thanksgiving ', 2, 15), ('@', 15, 16)]\n",
      "processing changed token: ('@', 15, 16)\n",
      "No handler for token: @\n",
      "\n",
      "processing: - Thanksgiving @s 11/26\n",
      "entry to tokens:\n",
      "   |12345678901234567890123|\n",
      "   |- Thanksgiving @s 11/26|\n",
      "   [('-', 0, 1), ('Thanksgiving ', 2, 15), ('@s 11/26', 15, 23)]\n",
      "processing changed token: ('@s 11/26', 15, 23)\n",
      "Dispatching token: @s 11/26 as s\n",
      "Processing datetime token: @s 11/26\n",
      "\n",
      "processing: - Thanksgiving @s 2010/11/26 \n",
      "entry to tokens:\n",
      "   |12345678901234567890123456789|\n",
      "   |- Thanksgiving @s 2010/11/26 |\n",
      "   [('-', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29)]\n",
      "processing changed token: ('@s 2010/11/26 ', 15, 29)\n",
      "Dispatching token: @s 2010/11/26  as s\n",
      "Processing datetime token: @s 2010/11/26 \n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 \n",
      "entry to tokens:\n",
      "   |12345678901234567890123456789|\n",
      "   |* Thanksgiving @s 2010/11/26 |\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29)]\n",
      "processing changed token: ('*', 0, 1)\n",
      "Dispatching token: * as itemtype\n",
      "Processing item type token: *\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @\n",
      "entry to tokens:\n",
      "   |123456789012345678901234567890|\n",
      "   |* Thanksgiving @s 2010/11/26 @|\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@', 29, 30)]\n",
      "processing changed token: ('@', 29, 30)\n",
      "No handler for token: @\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r \n",
      "entry to tokens:\n",
      "   |12345678901234567890123456789012|\n",
      "   |* Thanksgiving @s 2010/11/26 @r |\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r ', 29, 32)]\n",
      "processing changed token: ('@r ', 29, 32)\n",
      "Dispatching token: @r  as r\n",
      "Processing rrule token: @r \n",
      "do_rrule parts = ['@r']\n",
      "Error processing token 'r': Missing rrule frequency: @r \n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r z\n",
      "entry to tokens:\n",
      "   |123456789012345678901234567890123|\n",
      "   |* Thanksgiving @s 2010/11/26 @r z|\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r z', 29, 33)]\n",
      "processing changed token: ('@r z', 29, 33)\n",
      "Dispatching token: @r z as r\n",
      "Processing rrule token: @r z\n",
      "do_rrule parts = ['@r', 'z']\n",
      "Error processing token 'r': 'z', is not one of the supported frequencies from: \n",
      "   y: YEARLY, m: MONTHLY, w: WEEKLY, d: DAILY, h: HOURLY, n: MINUTELY\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r y \n",
      "entry to tokens:\n",
      "   |1234567890123456789012345678901234|\n",
      "   |* Thanksgiving @s 2010/11/26 @r y |\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r y ', 29, 34)]\n",
      "processing changed token: ('@r y ', 29, 34)\n",
      "Dispatching token: @r y  as r\n",
      "Processing rrule token: @r y \n",
      "do_rrule parts = ['@r', 'y']\n",
      "self.rrule_tokens = [('@r y ', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'} to self.rrules\n",
      "finalizing rruleset using len(self.rrule_tokens) = 1; len(components) = 0; len(rruleset_str) = 0\n",
      "finalizing rrule token = ('@r y ', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'}):  _ = '@r y ' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'}\n",
      "success = True\n",
      "   rruleset_str = DTSTART:20101126T000000\n",
      "RRULE:FREQ=YEARLY\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r y &\n",
      "entry to tokens:\n",
      "   |12345678901234567890123456789012345|\n",
      "   |* Thanksgiving @s 2010/11/26 @r y &|\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r y &', 29, 35)]\n",
      "processing changed token: ('@r y &', 29, 35)\n",
      "Dispatching token: @r y & as r\n",
      "Processing rrule token: @r y &\n",
      "do_rrule parts = ['@r', 'y', '&']\n",
      "self.rrule_tokens = [('@r y ', {}), ('@r y &', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'} to self.rrules\n",
      "finalizing rruleset using len(self.rrule_tokens) = 2; len(components) = 0; len(rruleset_str) = 0\n",
      "finalizing rrule token = ('@r y ', {}):  _ = '@r y ' with rrule_params = {}\n",
      "finalizing rrule token = ('@r y &', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'}):  _ = '@r y &' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'}\n",
      "success = True\n",
      "   rruleset_str = \n",
      "DTSTART:20101126T000000\n",
      "RRULE:FREQ=YEARLY\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r y &M 11 \n",
      "entry to tokens:\n",
      "   |1234567890123456789012345678901234567890|\n",
      "   |* Thanksgiving @s 2010/11/26 @r y &M 11 |\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r y &M 11 ', 29, 40)]\n",
      "processing changed token: ('@r y &M 11 ', 29, 40)\n",
      "Dispatching token: @r y &M 11  as r\n",
      "Processing rrule token: @r y &M 11 \n",
      "do_rrule parts = ['@r', 'y', '&M', '11']\n",
      "self.rrule_tokens = [('@r y ', {}), ('@r y &', {}), ('@r y &M 11 ', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'} to self.rrules\n",
      "token_type = 'rM': token_value = '11'\n",
      "11 => BYMONTH=11\n",
      "finalizing rruleset using len(self.rrule_tokens) = 3; len(components) = 0; len(rruleset_str) = 0\n",
      "finalizing rrule token = ('@r y ', {}):  _ = '@r y ' with rrule_params = {}\n",
      "finalizing rrule token = ('@r y &', {}):  _ = '@r y &' with rrule_params = {}\n",
      "finalizing rrule token = ('@r y &M 11 ', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11'}):  _ = '@r y &M 11 ' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11'}\n",
      "success = True\n",
      "   rruleset_str = \n",
      "\n",
      "DTSTART:20101126T000000\n",
      "RRULE:FREQ=YEARLY;BYMONTH=11\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r y &M 11 &w +4\n",
      "entry to tokens:\n",
      "   |123456789012345678901234567890123456789012345|\n",
      "   |* Thanksgiving @s 2010/11/26 @r y &M 11 &w +4|\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r y &M 11 &w +4', 29, 45)]\n",
      "processing changed token: ('@r y &M 11 &w +4', 29, 45)\n",
      "Dispatching token: @r y &M 11 &w +4 as r\n",
      "Processing rrule token: @r y &M 11 &w +4\n",
      "do_rrule parts = ['@r', 'y', '&M', '11', '&w', '+4']\n",
      "self.rrule_tokens = [('@r y ', {}), ('@r y &', {}), ('@r y &M 11 ', {'rM': 'BYMONTH=11'}), ('@r y &M 11 &w +4', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'} to self.rrules\n",
      "token_type = 'rM': token_value = '11'\n",
      "11 => BYMONTH=11\n",
      "token_type = 'rw': token_value = '+4'\n",
      "in do_weekdays with wkd_str = |+4|\n",
      "all = ['+4'], bad = ['+4']\n",
      "splitting +4\n",
      "x = '+4', i = |+|, w = |4|\n",
      "   e = ValueError(\"invalid literal for int() with base 10: '+'\")\n",
      "\n",
      "processing: * Thanksgiving @s 2010/11/26 @r y &M 11 &w +4TH\n",
      "entry to tokens:\n",
      "   |12345678901234567890123456789012345678901234567|\n",
      "   |* Thanksgiving @s 2010/11/26 @r y &M 11 &w +4TH|\n",
      "   [('*', 0, 1), ('Thanksgiving ', 2, 15), ('@s 2010/11/26 ', 15, 29), ('@r y &M 11 &w +4TH', 29, 47)]\n",
      "processing changed token: ('@r y &M 11 &w +4TH', 29, 47)\n",
      "Dispatching token: @r y &M 11 &w +4TH as r\n",
      "Processing rrule token: @r y &M 11 &w +4TH\n",
      "do_rrule parts = ['@r', 'y', '&M', '11', '&w', '+4TH']\n",
      "self.rrule_tokens = [('@r y ', {}), ('@r y &', {}), ('@r y &M 11 ', {'rM': 'BYMONTH=11'}), ('@r y &M 11 &w +4', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11'}), ('@r y &M 11 &w +4TH', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000'} to self.rrules\n",
      "token_type = 'rM': token_value = '11'\n",
      "11 => BYMONTH=11\n",
      "token_type = 'rw': token_value = '+4TH'\n",
      "in do_weekdays with wkd_str = |+4TH|\n",
      "all = ['+4TH'], bad = []\n",
      "+4TH => BYDAY=+4TH\n",
      "finalizing rruleset using len(self.rrule_tokens) = 5; len(components) = 0; len(rruleset_str) = 0\n",
      "finalizing rrule token = ('@r y ', {}):  _ = '@r y ' with rrule_params = {}\n",
      "finalizing rrule token = ('@r y &', {}):  _ = '@r y &' with rrule_params = {}\n",
      "finalizing rrule token = ('@r y &M 11 ', {'rM': 'BYMONTH=11'}):  _ = '@r y &M 11 ' with rrule_params = {'rM': 'BYMONTH=11'}\n",
      "finalizing rrule token = ('@r y &M 11 &w +4', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11'}):  _ = '@r y &M 11 &w +4' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11'}\n",
      "finalizing rrule token = ('@r y &M 11 &w +4TH', {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11', 'rw': 'BYDAY=+4TH'}):  _ = '@r y &M 11 &w +4TH' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20101126T000000', 'rM': 'BYMONTH=11', 'rw': 'BYDAY=+4TH'}\n",
      "success = True\n",
      "   rruleset_str = \n",
      "\n",
      "BYMONTH=11\n",
      "DTSTART:20101126T000000\n",
      "RRULE:FREQ=YEARLY;BYMONTH=11\n",
      "DTSTART:20101126T000000\n",
      "RRULE:FREQ=YEARLY;BYMONTH=11;BYDAY=+4TH\n",
      "entry to tokens:\n",
      "   |1234567890123456789012345678901234567890123456789012345678|\n",
      "   |* multiple rules @s wed 8a @r y &M 11 &w +4TH @r m &w +2TH|\n",
      "   [('*', 0, 1), ('multiple rules ', 2, 17), ('@s wed 8a ', 17, 27), ('@r y &M 11 &w +4TH ', 27, 46), ('@r m &w +2TH', 46, 58)]\n",
      "Dispatching token: * as itemtype\n",
      "Processing item type token: *\n",
      "Dispatching token: multiple rules  as summary\n",
      "Processing summary token: multiple rules \n",
      "Dispatching token: @s wed 8a  as s\n",
      "Processing datetime token: @s wed 8a \n",
      "Dispatching token: @r y &M 11 &w +4TH  as r\n",
      "Processing rrule token: @r y &M 11 &w +4TH \n",
      "do_rrule parts = ['@r', 'y', '&M', '11', '&w', '+4TH']\n",
      "self.rrule_tokens = [('@r y &M 11 &w +4TH ', {'FREQ': 'YEARLY', 'DTSTART': '20240731T000000'})]\n",
      "appending {'FREQ': 'YEARLY', 'DTSTART': '20240731T000000'} to self.rrules\n",
      "token_type = 'rM': token_value = '11'\n",
      "11 => BYMONTH=11\n",
      "token_type = 'rw': token_value = '+4TH'\n",
      "in do_weekdays with wkd_str = |+4TH|\n",
      "all = ['+4TH'], bad = []\n",
      "+4TH => BYDAY=+4TH\n",
      "Dispatching token: @r m &w +2TH as r\n",
      "Processing rrule token: @r m &w +2TH\n",
      "do_rrule parts = ['@r', 'm', '&w', '+2TH']\n",
      "self.rrule_tokens = [('@r y &M 11 &w +4TH ', {'FREQ': 'YEARLY', 'DTSTART': '20240731T000000', 'rM': 'BYMONTH=11', 'rw': 'BYDAY=+4TH'}), ('@r m &w +2TH', {'FREQ': 'MONTHLY', 'DTSTART': '20240731T000000'})]\n",
      "appending {'FREQ': 'MONTHLY', 'DTSTART': '20240731T000000'} to self.rrules\n",
      "token_type = 'rw': token_value = '+2TH'\n",
      "in do_weekdays with wkd_str = |+2TH|\n",
      "all = ['+2TH'], bad = []\n",
      "+2TH => BYDAY=+2TH\n",
      "finalizing rruleset using len(self.rrule_tokens) = 2; len(components) = 0; len(rruleset_str) = 0\n",
      "finalizing rrule token = ('@r y &M 11 &w +4TH ', {'FREQ': 'YEARLY', 'DTSTART': '20240731T000000', 'rM': 'BYMONTH=11', 'rw': 'BYDAY=+4TH'}):  _ = '@r y &M 11 &w +4TH ' with rrule_params = {'FREQ': 'YEARLY', 'DTSTART': '20240731T000000', 'rM': 'BYMONTH=11', 'rw': 'BYDAY=+4TH'}\n",
      "finalizing rrule token = ('@r m &w +2TH', {'FREQ': 'MONTHLY', 'DTSTART': '20240731T000000', 'rw': 'BYDAY=+2TH'}):  _ = '@r m &w +2TH' with rrule_params = {'FREQ': 'MONTHLY', 'DTSTART': '20240731T000000', 'rw': 'BYDAY=+2TH'}\n",
      "success = True\n",
      "rruleset_str:\n",
      "DTSTART:20240731T000000\n",
      "RRULE:FREQ=YEARLY;BYMONTH=11;BYDAY=+4TH\n",
      "DTSTART:20240731T000000\n",
      "RRULE:FREQ=MONTHLY;BYDAY=+2TH\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "from dateutil.rrule import rruleset\n",
    "from dateutil.parser import parse\n",
    "\n",
    "class Item:\n",
    "    token_keys = {\n",
    "        'itemtype': [\n",
    "            'item type',\n",
    "            'character from * (event), - (task), % (journal), ~ (goal), + (track) or ! (inbox)',\n",
    "            'do_itemtype',\n",
    "        ],\n",
    "        'summary': [\n",
    "            'summary',\n",
    "            \"brief item description. Append an '@' to add an option.\",\n",
    "            'do_summary',\n",
    "        ],\n",
    "        's': ['scheduled', 'starting date or datetime', 'do_datetime'],\n",
    "        'r': ['recurrence', 'recurrence rule', 'do_rrule'],\n",
    "        'j': ['journal', 'journal entry', 'do_j'],\n",
    "        '+': ['rdate', 'recurrence dates', 'do_rdate'],\n",
    "        '-': ['exdate', 'exception dates', 'do_exdate'],\n",
    "        'rw': ['weekdays', 'list from SU, MO, ..., SA, possibly prepended with a positive or negative integer', 'do_weekdays'],\n",
    "        'rM': ['months', 'list of integers in 1 ... 12', 'do_months'],\n",
    "        # Add more `&` token handlers for @j here as needed\n",
    "    }\n",
    "\n",
    "    wkd_list = ['SU', 'MO', 'TU', 'WE', 'TH', 'FR', 'SA']\n",
    "    wkd_str = ', '.join(wkd_list)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.entry = \"\"\n",
    "        self.tokens = []\n",
    "        self.previous_entry = \"\"\n",
    "        self.parsed_data = {}\n",
    "        self.previous_tokens = []\n",
    "        self.rrule_tokens = []\n",
    "        self.job_tokens = []\n",
    "        self.rrules = []\n",
    "        self.rdates = []\n",
    "        self.exdates = []\n",
    "        self.dtstart = None\n",
    "\n",
    "    def parse_input(self, entry: str):\n",
    "        \"\"\"\n",
    "        Parses the input string to extract tokens, then processes and validates the tokens.\n",
    "        \"\"\"\n",
    "        digits = '1234567890' * ceil(len(entry) / 10)\n",
    "        self._tokenize(entry)\n",
    "        print(f'entry to tokens:\\n   |{digits[:len(entry)]}|\\n   |{entry}|\\n   {self.tokens}')\n",
    "        self._parse_tokens(entry)\n",
    "        self.previous_entry = entry\n",
    "        self.previous_tokens = self.tokens.copy()\n",
    "\n",
    "    def _tokenize(self, entry: str):\n",
    "        self.entry = entry\n",
    "        pattern = r'(@\\w+ [^@]+)|(^\\S+)|(\\S[^@]*)'\n",
    "        matches = re.finditer(pattern, self.entry)\n",
    "        tokens_with_positions = []\n",
    "        for match in matches:\n",
    "            # Get the matched token\n",
    "            token = match.group(0)\n",
    "            # Get the start and end positions\n",
    "            start_pos = match.start()\n",
    "            end_pos = match.end()\n",
    "            # Append the token and its positions as a tuple\n",
    "            tokens_with_positions.append((token, start_pos, end_pos))\n",
    "        self.tokens = tokens_with_positions\n",
    "\n",
    "    def _parse_tokens(self, entry: str):\n",
    "        if not self.previous_entry:\n",
    "            # If there is no previous entry, parse all tokens\n",
    "            self._parse_all_tokens()\n",
    "            return\n",
    "\n",
    "        # Identify the affected tokens based on the change\n",
    "        changes = self._find_changes(self.previous_entry, entry)\n",
    "        affected_tokens = self._identify_affected_tokens(changes)\n",
    "\n",
    "        # Parse only the affected tokens\n",
    "        for token_info in affected_tokens:\n",
    "            token, start_pos, end_pos = token_info\n",
    "            # Check if the token has actually changed\n",
    "            if self._token_has_changed(token_info):\n",
    "                print(f\"processing changed token: {token_info}\")\n",
    "                if start_pos == 0:\n",
    "                    self._dispatch_token(token, start_pos, end_pos, 'itemtype')\n",
    "                elif start_pos == 2:\n",
    "                    self._dispatch_token(token, start_pos, end_pos, 'summary')\n",
    "                else:\n",
    "                    self._dispatch_token(token, start_pos, end_pos)\n",
    "\n",
    "    def _parse_all_tokens(self):\n",
    "        for i, token_info in enumerate(self.tokens):\n",
    "            token, start_pos, end_pos = token_info\n",
    "            if i == 0:\n",
    "                self._dispatch_token(token, start_pos, end_pos, 'itemtype')\n",
    "            elif i == 1:\n",
    "                self._dispatch_token(token, start_pos, end_pos, 'summary')\n",
    "            else:\n",
    "                token_type = token.split()[0][1:]  # Extract token type (e.g., 's' from '@s')\n",
    "                self._dispatch_token(token, start_pos, end_pos, token_type)\n",
    "\n",
    "    def _find_changes(self, previous: str, current: str):\n",
    "        # Find the range of changes between the previous and current strings\n",
    "        start = 0\n",
    "        while start < len(previous) and start < len(current) and previous[start] == current[start]:\n",
    "            start += 1\n",
    "\n",
    "        end_prev = len(previous)\n",
    "        end_curr = len(current)\n",
    "\n",
    "        while end_prev > start and end_curr > start and previous[end_prev - 1] == current[end_curr - 1]:\n",
    "            end_prev -= 1\n",
    "            end_curr -= 1\n",
    "\n",
    "        return start, end_curr\n",
    "\n",
    "    def _identify_affected_tokens(self, changes):\n",
    "        start, end = changes\n",
    "        affected_tokens = []\n",
    "        for token_info in self.tokens:\n",
    "            token, start_pos, end_pos = token_info\n",
    "            if start <= end_pos and end >= start_pos:\n",
    "                affected_tokens.append(token_info)\n",
    "        return affected_tokens\n",
    "\n",
    "    def _token_has_changed(self, token_info):\n",
    "        return token_info not in self.previous_tokens\n",
    "\n",
    "    def _dispatch_token(self, token, start_pos, end_pos, token_type=None):\n",
    "        if token_type is None:\n",
    "            if token.startswith('@'):\n",
    "                token_type = token.split()[0][1:]  # Extract token type (e.g., 's' from '@s')\n",
    "            else:\n",
    "                token_type = token\n",
    "        if token_type in self.token_keys:\n",
    "            print(f\"Dispatching token: {token} as {token_type}\")\n",
    "            method_name = self.token_keys[token_type][2]\n",
    "            method = getattr(self, method_name)\n",
    "            is_valid, result, sub_tokens = method(token)\n",
    "            if is_valid:\n",
    "                if token_type == 'r':\n",
    "                    print(f\"appending {result} to self.rrules\")\n",
    "                    self.rrules.append(result)\n",
    "                    self._dispatch_sub_tokens(sub_tokens, 'r')\n",
    "                elif token_type == 'j':\n",
    "                    self.job_tokens.append(result)\n",
    "                    self._dispatch_sub_tokens(sub_tokens, 'j')\n",
    "                elif token_type == '+':\n",
    "                    self.rdates.extend(result)\n",
    "                elif token_type == '-':\n",
    "                    self.exdates.extend(result)\n",
    "                else:\n",
    "                    self.parsed_data[token_type] = result\n",
    "            else:\n",
    "                print(f\"Error processing token '{token_type}': {result}\")\n",
    "        else:\n",
    "            print(f\"No handler for token: {token}\")\n",
    "\n",
    "    def _dispatch_sub_tokens(self, sub_tokens, prefix):\n",
    "        for part in sub_tokens:\n",
    "            if part.startswith('&'):\n",
    "                token_type = prefix + part[1:2]  # Prepend prefix to token type\n",
    "                token_value = part[2:].strip()\n",
    "                print(f\"token_type = '{token_type}': token_value = '{token_value}'\")\n",
    "                if token_type in self.token_keys:\n",
    "                    method_name = self.token_keys[token_type][2]\n",
    "                    method = getattr(self, method_name)\n",
    "                    is_valid, result = method(token_value)\n",
    "                    print(f\"{token_value} => {result}\")\n",
    "                    if is_valid:\n",
    "                        self.rrule_tokens[-1][1][token_type] = result\n",
    "                    else:\n",
    "                        print(f\"Error processing sub-token '{token_type}': {result}\")\n",
    "                else:\n",
    "                    print(f\"No handler for sub-token: {token_type}\")\n",
    "\n",
    "    def _validate(self):\n",
    "        # Overall validation logic if needed\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def do_itemtype(cls, token):\n",
    "        # Process item type token\n",
    "        print(f\"Processing item type token: {token}\")\n",
    "        valid_itemtypes = {'*', '-', '%', '~', '+', '!'}\n",
    "        itemtype = token[0]\n",
    "        if itemtype in valid_itemtypes:\n",
    "            return True, itemtype, []\n",
    "        else:\n",
    "            return False, f\"Invalid item type: {itemtype}\", []\n",
    "\n",
    "    @classmethod\n",
    "    def do_summary(cls, token):\n",
    "        # Process summary token\n",
    "        print(f\"Processing summary token: {token}\")\n",
    "        if len(token) >= 1:\n",
    "            return True, token.strip(), []\n",
    "        else:\n",
    "            return False, \"Summary cannot be empty\", []\n",
    "\n",
    "    def do_datetime(self, token):\n",
    "        # Process datetime token\n",
    "        print(f\"Processing datetime token: {token}\")\n",
    "        try:\n",
    "            datetime_str = token.split()[1]\n",
    "            datetime_obj = parse(datetime_str)\n",
    "            self.dtstart = datetime_obj\n",
    "            return True, datetime_obj, []\n",
    "        except ValueError as e:\n",
    "            return False, f\"Invalid datetime: {datetime_str}. Error: {e}\", []\n",
    "\n",
    "    def do_rrule(self, token):\n",
    "        # Process rrule token\n",
    "        print(f\"Processing rrule token: {token}\")\n",
    "        freq_map = dict(\n",
    "            y='YEARLY', m='MONTHLY', w='WEEKLY', d='DAILY', h='HOURLY', n='MINUTELY')\n",
    "        parts = token.split()\n",
    "        print(f\"do_rrule {parts = }\")\n",
    "        if len(parts) < 2:\n",
    "            return False, f\"Missing rrule frequency: {token}\", []\n",
    "        elif parts[1] not in freq_map:\n",
    "            keys = \", \".join([f\"{k}: {v}\" for k, v in freq_map.items()])\n",
    "            return False, f\"'{parts[1]}', is not one of the supported frequencies from: \\n   {keys}\", []\n",
    "        freq = freq_map[parts[1]]\n",
    "        rrule_params = {'FREQ': freq}\n",
    "        if self.dtstart:\n",
    "            rrule_params['DTSTART'] = self.dtstart.strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "        # Collect & tokens that follow @r\n",
    "        sub_tokens = self._extract_sub_tokens(token, '&')\n",
    "\n",
    "        self.rrule_tokens.append((token, rrule_params))\n",
    "        print(f\"{self.rrule_tokens = }\")\n",
    "        return True, rrule_params, sub_tokens\n",
    "\n",
    "    def do_job(self, token):\n",
    "        # Process journal token\n",
    "        print(f\"Processing journal token: {token}\")\n",
    "        journal_params = {}\n",
    "\n",
    "        # Collect & tokens that follow @j\n",
    "        sub_tokens = self._extract_sub_tokens(token, '&')\n",
    "\n",
    "        self.job_tokens.append((token, journal_params))\n",
    "        return True, journal_params, sub_tokens\n",
    "\n",
    "    def _extract_sub_tokens(self, token, delimiter):\n",
    "        # Use regex to extract sub-tokens\n",
    "        pattern = rf'({delimiter}\\w+ \\S+)'\n",
    "        matches = re.findall(pattern, token)\n",
    "        return matches\n",
    "\n",
    "    @classmethod\n",
    "    def do_weekdays(cls, wkd_str: str):\n",
    "        \"\"\"\n",
    "        Converts a string representation of weekdays into a list of rrule objects.\n",
    "        \"\"\"\n",
    "        wkd_str = wkd_str.upper()\n",
    "        wkd_regex = r'(?<![\\w-])([+-][1-4])?(MO|TU|WE|TH|FR|SA|SU)(?!\\w)'\n",
    "        print(f\"in do_weekdays with wkd_str = |{wkd_str}|\")\n",
    "        matches = re.findall(wkd_regex, wkd_str)\n",
    "        _ = [f\"{x[0]}{x[1]}\" for x in matches]\n",
    "        all = [x.strip() for x in wkd_str.split(',')]\n",
    "        bad = [x for x in all if x not in _]\n",
    "        problem_str = \"\"\n",
    "        problems = []\n",
    "        print(f\"{all = }, {bad = }\")\n",
    "        for x in bad:\n",
    "            probs = []\n",
    "            print(f\"splitting {x}\")\n",
    "            i, w = cls.split_int_str(x)\n",
    "            print(f\"{x = }, i = |{i}|, w = |{w}|\")\n",
    "            if i is not None:\n",
    "                abs_i = abs(int(i))\n",
    "                if abs_i > 4 or abs_i == 0:\n",
    "                    probs.append(f\"{i} must be between -4 and -1 or between +1 and +4\")\n",
    "                elif not (i.startswith('+') or i.startswith('-')):\n",
    "                    probs.append(f\"{i} must begin with '+' or '-'\")\n",
    "            w = w.strip()\n",
    "            if not w:\n",
    "                probs.append(f\"Missing weekday abbreviation from {cls.wkd_str}\")\n",
    "            elif w not in cls.wkd_list:\n",
    "                probs.append(f\"{w} must be a weekday abbreviation from {cls.wkd_str}\")\n",
    "            if probs:\n",
    "                problems.append(f\"In '{x}': {', '.join(probs)}\")\n",
    "            else:\n",
    "                # undiagnosed problem\n",
    "                problems.append(f\"{x} is invalid\")\n",
    "        if problems:\n",
    "            problem_str = f\"Problem entries: {', '.join(bad)}\\n{'\\n'.join(problems)}\"\n",
    "        good = []\n",
    "        for x in matches:\n",
    "            s = f\"{x[0]}{x[1]}\" if x[0] else f\"{x[1]}\"\n",
    "            good.append(s)\n",
    "        good_str = ','.join(good)\n",
    "        if problem_str:\n",
    "            return False, f\"{problem_str}\\n{good_str}\"\n",
    "        else:\n",
    "            return True, f\"BYDAY={good_str}\"\n",
    "\n",
    "    @classmethod\n",
    "    def do_months(cls, arg):\n",
    "        \"\"\"\n",
    "        Process a comma separated list of integer month numbers from 1, 2, ..., 12\n",
    "        \"\"\"\n",
    "        monthsstr = 'months: a comma separated list of integer month numbers from 1, 2, ..., 12'\n",
    "        if arg:\n",
    "            args = arg.split(',')\n",
    "            ok, res = cls.integer_list(args, 0, 12, False, '')\n",
    "            if ok:\n",
    "                obj = res\n",
    "                rep = f'{arg}'\n",
    "            else:\n",
    "                obj = None\n",
    "                rep = f'invalid months: {res}. Required for {monthsstr}'\n",
    "        else:\n",
    "            obj = None\n",
    "            rep = monthsstr\n",
    "        if obj is None:\n",
    "            return False, rep\n",
    "\n",
    "        return True, f\"BYMONTH={rep}\"\n",
    "\n",
    "    @classmethod\n",
    "    def integer(cls, arg, min, max, zero, typ=None):\n",
    "        \"\"\"\n",
    "        :param arg: integer\n",
    "        :param min: minimum allowed or None\n",
    "        :param max: maximum allowed or None\n",
    "        :param zero: zero not allowed if False\n",
    "        :param typ: label for message\n",
    "        :return: (True, integer) or (False, message)\n",
    "        >>> integer(-2, -10, 8, False, 'integer_test')\n",
    "        (True, -2)\n",
    "        >>> integer(-2, 0, 8, False, 'integer_test')\n",
    "        (False, 'integer_test: -2 is less than the allowed minimum')\n",
    "        \"\"\"\n",
    "        msg = ''\n",
    "        try:\n",
    "            arg = int(arg)\n",
    "        except:\n",
    "            if typ:\n",
    "                return False, '{}: {}'.format(typ, arg)\n",
    "            else:\n",
    "                return False, arg\n",
    "        if min is not None and arg < min:\n",
    "            msg = '{} is less than the allowed minimum'.format(arg)\n",
    "        elif max is not None and arg > max:\n",
    "            msg = '{} is greater than the allowed maximum'.format(arg)\n",
    "        elif not zero and arg == 0:\n",
    "            msg = '0 is not allowed'\n",
    "        if msg:\n",
    "            if typ:\n",
    "                return False, '{}: {}'.format(typ, msg)\n",
    "            else:\n",
    "                return False, msg\n",
    "        else:\n",
    "            return True, arg\n",
    "\n",
    "    @classmethod\n",
    "    def integer_list(cls, arg, min, max, zero, typ=None):\n",
    "        \"\"\"\n",
    "        :param arg: comma separated list of integers\n",
    "        :param min: minimum allowed or None\n",
    "        :param max: maximum allowed or None\n",
    "        :param zero: zero not allowed if False\n",
    "        :param typ: label for message\n",
    "        :return: (True, list of integers) or (False, messages)\n",
    "        >>> integer_list([-13, -10, 0, \"2\", 27], -12, +20, True, 'integer_list test')\n",
    "        (False, 'integer_list test: -13 is less than the allowed minimum; 27 is greater than the allowed maximum')\n",
    "        >>> integer_list([0, 1, 2, 3, 4], 1, 3, True, \"integer_list test\")\n",
    "        (False, 'integer_list test: 0 is less than the allowed minimum; 4 is greater than the allowed maximum')\n",
    "        >>> integer_list(\"-1, 1, two, 3\", None, None, True, \"integer_list test\")\n",
    "        (False, 'integer_list test: -1, 1, two, 3')\n",
    "        >>> integer_list([1, \"2\", 3], None, None, True, \"integer_list test\")\n",
    "        (True, [1, 2, 3])\n",
    "        \"\"\"\n",
    "        if type(arg) == str:\n",
    "            try:\n",
    "                args = [int(x) for x in arg.split(',')]\n",
    "            except:\n",
    "                if typ:\n",
    "                    return False, '{}: {}'.format(typ, arg)\n",
    "                else:\n",
    "                    return False, arg\n",
    "        elif type(arg) == list:\n",
    "            try:\n",
    "                args = [int(x) for x in arg]\n",
    "            except:\n",
    "                if typ:\n",
    "                    return False, '{}: {}'.format(typ, arg)\n",
    "                else:\n",
    "                    return False, arg\n",
    "        elif type(arg) == int:\n",
    "            args = [arg]\n",
    "        msg = []\n",
    "        ret = []\n",
    "        for arg in args:\n",
    "            ok, res = cls.integer(arg, min, max, zero, None)\n",
    "            if ok:\n",
    "                ret.append(res)\n",
    "            else:\n",
    "                msg.append(res)\n",
    "        if msg:\n",
    "            if typ:\n",
    "                return False, '{}: {}'.format(typ, '; '.join(msg))\n",
    "            else:\n",
    "                return False, '; '.join(msg)\n",
    "        else:\n",
    "            return True, ret\n",
    "\n",
    "    @classmethod\n",
    "    def split_int_str(cls, s):\n",
    "        match = re.match(r'^([+-]?\\d*)(.{1,})$', s)\n",
    "        if match:\n",
    "            integer_part = match.group(1)\n",
    "            string_part = match.group(2)\n",
    "            # Convert integer_part to an integer if it's not empty, otherwise None\n",
    "            integer_part = integer_part if integer_part else None\n",
    "            string_part = string_part if string_part else None\n",
    "            return integer_part, string_part\n",
    "        return None, None  # Default case if no match is found\n",
    "\n",
    "    def do_rdate(self, token):\n",
    "        # Process rdate token\n",
    "        print(f\"Processing rdate token: {token}\")\n",
    "        parts = token.split()\n",
    "        try:\n",
    "            dates = [parse(dt) for dt in parts[1].split(',')]\n",
    "            return True, dates, []\n",
    "        except ValueError as e:\n",
    "            return False, f\"Invalid rdate: {parts[1]}. Error: {e}\", []\n",
    "\n",
    "    def do_exdate(self, token):\n",
    "        # Process exdate token\n",
    "        print(f\"Processing exdate token: {token}\")\n",
    "        parts = token.split()\n",
    "        try:\n",
    "            dates = [parse(dt) for dt in parts[1].split(',')]\n",
    "            return True, dates, []\n",
    "        except ValueError as e:\n",
    "            return False, f\"Invalid exdate: {parts[1]}. Error: {e}\", []\n",
    "\n",
    "    def finalize_rruleset(self):\n",
    "        # Finalize the rruleset after collecting all related tokens\n",
    "        if not self.rrule_tokens:\n",
    "            return False, \"No rrule tokens to process\"\n",
    "\n",
    "        components = []\n",
    "        rruleset_str = \"\"\n",
    "        print(f\"finalizing rruleset using {len(self.rrule_tokens) = }; {len(components) = }; {len(rruleset_str) = }\")\n",
    "        for token in self.rrule_tokens:\n",
    "            rule_parts = []\n",
    "            _, rrule_params = token\n",
    "            print(f\"finalizing rrule {token = }:  {_ = } with {rrule_params = }\")\n",
    "            dtstart = rrule_params.pop('DTSTART', None)\n",
    "            if dtstart:\n",
    "                components.append(f\"DTSTART:{dtstart}\")\n",
    "            freq = rrule_params.pop('FREQ', None)\n",
    "            if freq:\n",
    "                rule_parts = [f\"RRULE:FREQ={freq}\",]\n",
    "            for k, v in rrule_params.items():\n",
    "                if v:\n",
    "                    rule_parts.append(f\"{v}\")\n",
    "\n",
    "            rule = \";\".join(rule_parts)\n",
    "\n",
    "            components.append(rule)\n",
    "\n",
    "        for rdate in self.rdates:\n",
    "            components.append(f\"RDATE:{rdate.strftime('%Y%m%dT%H%M%S')}\")\n",
    "\n",
    "        for exdate in self.exdates:\n",
    "            components.append(f\"EXDATE:{exdate.strftime('%Y%m%dT%H%M%S')}\")\n",
    "\n",
    "        rruleset_str = \"\\n\".join(components)\n",
    "        self.parsed_data['rruleset'] = rruleset_str\n",
    "\n",
    "        # self.rrule_tokens = []\n",
    "        self.rdates = []\n",
    "        self.exdates = []\n",
    "        return True, rruleset_str\n",
    "\n",
    "# Example usage\n",
    "item = Item()\n",
    "partial_strings = [\n",
    "    \"\",\n",
    "    \"- \",\n",
    "    \"- T\",\n",
    "    \"- Thanksgiving \",\n",
    "    \"- Thanksgiving @\",\n",
    "    \"- Thanksgiving @s 11/26\",\n",
    "    \"- Thanksgiving @s 2010/11/26 \",\n",
    "    \"* Thanksgiving @s 2010/11/26 \",\n",
    "    \"* Thanksgiving @s 2010/11/26 @\",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r \",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r z\",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r y \",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r y &\",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r y &M 11 \",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r y &M 11 &w +4\",\n",
    "    \"* Thanksgiving @s 2010/11/26 @r y &M 11 &w +4TH\",\n",
    "]\n",
    "\n",
    "print(\"\\nparsing partial_strings\")\n",
    "for s in partial_strings:\n",
    "    print(f\"\\nprocessing: {s}\")\n",
    "    try:\n",
    "        item.parse_input(s)\n",
    "        if item.rrule_tokens:\n",
    "            success, rruleset_str = item.finalize_rruleset()\n",
    "            print(f\"{success = }\\n   rruleset_str = {rruleset_str}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   {e = }\")\n",
    "\n",
    "item2 = Item()\n",
    "item2.parse_input(\"* multiple rules @s wed 8a @r y &M 11 &w +4TH @r m &w +2TH\")\n",
    "if item2.rrule_tokens:\n",
    "    success, rruleset_str = item2.finalize_rruleset()\n",
    "    print(f\"{success = }\\nrruleset_str:\\n{rruleset_str}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_with_positions = [('@r y ', 0, 5), ('&M 11 ', 5, 11), ('&', 11, 12)]\n",
      "tokens_with_positions = [('@r y ', 0, 5), ('&M 11 ', 5, 11), ('&w +4TH', 11, 18)]\n",
      "tokens_with_positions = [('@j cut pieces ', 0, 14), ('&i b ', 14, 19), ('&p a', 19, 23)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_sub_tokens(entry):\n",
    "    pattern = r'(@\\w+ [^&]+)|(^\\S+)|(\\S[^&]*)'\n",
    "    matches = re.finditer(pattern, entry)\n",
    "    tokens_with_positions = []\n",
    "    for match in matches:\n",
    "        # Get the matched token\n",
    "        token = match.group(0)\n",
    "        # Get the start and end positions\n",
    "        start_pos = match.start()\n",
    "        end_pos = match.end()\n",
    "        # Append the token and its positions as a tuple\n",
    "        tokens_with_positions.append((token, start_pos, end_pos))\n",
    "    print(f\"{tokens_with_positions = }\")\n",
    "\n",
    "get_sub_tokens(\"@r y &M 11 &\")\n",
    "get_sub_tokens(\"@r y &M 11 &w +4TH\")\n",
    "get_sub_tokens(\"@j cut pieces &i b &p a\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View data \"rows\" are lists of hashes with keys for *doc_id*, *sort*, *groupby* (YrWk or path) and *columns*. \n",
    "\n",
    "- Note that sort must give an order consistent with groupby. E.g., sort by datetime will be consistent with groupby \"YrWk\".\n",
    "\n",
    "- Note also that groupby \"YrWk\" obviates the need for creating a hash with YrWk keys.\n",
    "\n",
    "As below, the list of hashes is sorted by the \"sort\" key using itemgetter and then grouped by the \"YrWk\" or \"path\" key using groupby. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 25\n",
      "  {'name': 'Charlie', 'age': 25}\n",
      "  {'name': 'Eve', 'age': 25}\n",
      "Age: 30\n",
      "  {'name': 'Alice', 'age': 30}\n",
      "  {'name': 'Bob', 'age': 30}\n",
      "  {'name': 'David', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import operator\n",
    "\n",
    "data = [\n",
    "    {'name': 'Alice', 'age': 30},\n",
    "    {'name': 'Bob', 'age': 30},\n",
    "    {'name': 'Charlie', 'age': 25},\n",
    "    {'name': 'David', 'age': 30},\n",
    "    {'name': 'Eve', 'age': 25}\n",
    "]\n",
    "\n",
    "# Sort the data by 'age' using operator.itemgetter\n",
    "data.sort(key=operator.itemgetter('age'))\n",
    "\n",
    "# Group by the 'age' key using operator.itemgetter\n",
    "grouped = itertools.groupby(data, key=operator.itemgetter('age'))\n",
    "\n",
    "for key, group in grouped:\n",
    "    print(f\"Age: {key}\")\n",
    "    for item in group:\n",
    "        print(f\"  {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@s 2024-08-07 4:00pm @r w &i 2 &w WE @r w &w MO @+ 2024-08-09 2:45pm @+ 2024-08-16 2:30pm @- 2024-08-21 4:00pm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class Item:\n",
    "    freq_map = dict(\n",
    "        y='YEARLY', m='MONTHLY', w='WEEKLY', d='DAILY', h='HOURLY', n='MINUTELY'\n",
    "    )\n",
    "\n",
    "    key_to_param = dict(\n",
    "        i='INTERVAL', c='COUNT', s='BYSETPOS', u='UNTIL', M='BYMONTH', m='BYMONTHDAY',\n",
    "        W='BYWEEKNO', w='BYDAY', h='BYHOUR', n='BYMINUTE', E='BYEASTER'\n",
    "    )\n",
    "\n",
    "    param_to_key = {v: k for k, v in key_to_param.items()}\n",
    "\n",
    "    def rrule_to_entry(self, rstr: str)->str:\n",
    "        # Split the input text into lines\n",
    "        lines = rstr.strip().split('\\n')\n",
    "\n",
    "        dtstart_list = []\n",
    "        rrule_list = []\n",
    "        rdate_list = []\n",
    "        exdate_list = []\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith(\"DTSTART:\"):\n",
    "                dtstart_str = line.replace(\"DTSTART:\", \"\")\n",
    "                dtstart_list.append(dtstart_str)\n",
    "            elif line.startswith(\"RRULE:\"):\n",
    "                rrule_str = line.replace(\"RRULE:\", \"\")\n",
    "                rrule_list.append(rrule_str)\n",
    "            elif line.startswith(\"RDATE:\"):\n",
    "                rdate_str = line.replace(\"RDATE:\", \"\")\n",
    "                rdate_list.extend(rdate_str.split(',')) # Split multiple RDATEs\n",
    "            elif line.startswith(\"EXDATE:\"):\n",
    "                exdate_str = line.replace(\"EXDATE:\", \"\")\n",
    "                exdate_list.extend(exdate_str.split(',')) # Split multiple EXDATEs\n",
    "\n",
    "        # Process DTSTART\n",
    "        dtstart_part = \"\"\n",
    "        if dtstart_list:\n",
    "            dtstart_date = datetime.strptime(dtstart_list[0], \"%Y%m%dT%H%M%S\")\n",
    "            dtstart_part = f\"@s {dtstart_date.strftime('%Y-%m-%d %-I:%M%p').lower()}\"\n",
    "\n",
    "        # Process RRULEs\n",
    "        rrule_parts = []\n",
    "        for rrule_str in rrule_list:\n",
    "            rrule_params = {}\n",
    "            for param in rrule_str.split(\";\"):\n",
    "                key, value = param.split(\"=\")\n",
    "                rrule_params[key] = value\n",
    "\n",
    "            freq_entry = list(self.freq_map.keys())[list(self.freq_map.values()).index(rrule_params['FREQ'])]\n",
    "            rrule_part = f\"@r {freq_entry}\"\n",
    "\n",
    "            for key, value in rrule_params.items():\n",
    "                if key == 'FREQ':\n",
    "                    continue\n",
    "                entry = self.param_to_key[key]\n",
    "                rrule_part += f\" &{entry} {value}\"\n",
    "\n",
    "            rrule_parts.append(rrule_part)\n",
    "\n",
    "        # Process RDATEs\n",
    "        rdate_parts = []\n",
    "        for rdate_str in rdate_list:\n",
    "            rdate_date = datetime.strptime(rdate_str, \"%Y%m%dT%H%M%S\")\n",
    "            rdate_parts.append(f\"@+ {rdate_date.strftime('%Y-%m-%d %-I:%M%p').lower()}\")\n",
    "\n",
    "        # Process EXDATEs\n",
    "        exdate_parts = []\n",
    "        for exdate_str in exdate_list:\n",
    "            exdate_date = datetime.strptime(exdate_str, \"%Y%m%dT%H%M%S\")\n",
    "            exdate_parts.append(f\"@- {exdate_date.strftime('%Y-%m-%d %-I:%M%p').lower()}\")\n",
    "\n",
    "        return f\"{dtstart_part} {' '.join(rrule_parts)} {' '.join(rdate_parts)} {' '.join(exdate_parts)}\"\n",
    "        # return f\"{' '.join(rrule_parts)} {' '.join(rdate_parts)} {' '.join(exdate_parts)}\"\n",
    "\n",
    "# Example usage\n",
    "item = Item()\n",
    "input_str = \"DTSTART:20240807T160000\\nRRULE:FREQ=WEEKLY;INTERVAL=2;BYDAY=WE\\nDTSTART:20240807T160000\\nRRULE:FREQ=WEEKLY;BYDAY=MO\\nRDATE:20240809T144500,20240816T143000\\nEXDATE:20240821T160000\"\n",
    "output_str = item.rrule_to_entry(input_str)\n",
    "\n",
    "print(output_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Buy groceries, Completed: False\n",
      "Task: Buy groceries, Completed: True\n"
     ]
    }
   ],
   "source": [
    "from ZODB import DB, FileStorage\n",
    "from persistent import Persistent\n",
    "import transaction\n",
    "\n",
    "# Define a simple persistent class\n",
    "class Task(Persistent):\n",
    "    def __init__(self, title, completed=False):\n",
    "        self.title = title\n",
    "        self.completed = completed\n",
    "\n",
    "    def mark_completed(self):\n",
    "        self.completed = True\n",
    "\n",
    "# Create a ZODB database stored in a file\n",
    "storage = FileStorage.FileStorage('tasks.fs')\n",
    "db = DB(storage)\n",
    "\n",
    "# Open a connection to the database\n",
    "connection = db.open()\n",
    "\n",
    "# Get the root object\n",
    "root = connection.root()\n",
    "\n",
    "# Add a new task to the database if it doesn't exist\n",
    "if 'tasks' not in root:\n",
    "    root['tasks'] = []\n",
    "\n",
    "# Create a new task and add it to the tasks list\n",
    "task = Task(title=\"Buy groceries\")\n",
    "root['tasks'].append(task)\n",
    "\n",
    "# Commit the transaction to save the changes\n",
    "transaction.commit()\n",
    "\n",
    "# Retrieve and display tasks from the database\n",
    "for task in root['tasks']:\n",
    "    print(f\"Task: {task.title}, Completed: {task.completed}\")\n",
    "\n",
    "# Mark the first task as completed and save\n",
    "root['tasks'][0].mark_completed()\n",
    "transaction.commit()\n",
    "\n",
    "# Display tasks again after marking the first as completed\n",
    "for task in root['tasks']:\n",
    "    print(f\"Task: {task.title}, Completed: {task.completed}\")\n",
    "\n",
    "# Close the connection and the database\n",
    "connection.close()\n",
    "db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
